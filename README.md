Data Pipeline Spotify: AnÃ¡lise Musical com Arquitetura MedalhÃ£o na AWS
[]

VisÃ£o Geral do Projeto
Este projeto demonstra a construÃ§Ã£o de um pipeline de dados robusto e escalÃ¡vel para anÃ¡lise de dados musicais da API do Spotify.Â  Utilizando a arquitetura MedalhÃ£o na AWS, o pipeline ingere dados brutos, os refina em camadas de qualidade crescente e, finalmente, os disponibiliza para visualizaÃ§Ã£o interativa em dashboards.

O objetivo principal deste projeto Ã© apresentar um portfÃ³lio impressionante no LinkedIn, destacando habilidades em engenharia de dados com tecnologias modernas e demandadas no mercado.

Tecnologias Utilizadas:

*Â  Â OrquestraÃ§Ã£o e ETL/ELT: Mage.ai - Plataforma moderna para orquestraÃ§Ã£o de pipelines de dados, ETL/ELT visual e colaborativo.
*Â  Â Processamento DistribuÃ­do: Spark (integrado ao Mage.ai) -Â  Motor de processamento rÃ¡pido e escalÃ¡vel para grandes volumes de dados.
*Â  Â Modelagem e TransformaÃ§Ã£o de Dados: DBT (Data Build Tool) (integrado ao Mage.ai) - Ferramenta para transformaÃ§Ã£o de dados declarativa e versionada, com foco em qualidade e testes.
*Â  Â Data Warehouse AnalÃ­tico: ClickHouse - Banco de dados colunar de alta performance, ideal para workloads analÃ­ticos e visualizaÃ§Ã£o rÃ¡pida.
*Â  Â Data Lake: S3 AWS - Armazenamento de objetos escalÃ¡vel e durÃ¡vel na AWS, utilizado como Data Lake para todas as camadas do MedalhÃ£o.
*Â  Â VisualizaÃ§Ã£o de Dados: Superset - Plataforma de visualizaÃ§Ã£o de dados interativa e intuitiva para criaÃ§Ã£o de dashboards.
*Â  Â Fonte de Dados: Spotify API - API REST do Spotify para extraÃ§Ã£o de dados musicais.
*Â  Â Linguagens: Python, SQL
*Â  Â Formatos de Dados: JSON, Parquet

Arquitetura do Projeto (MedalhÃ£o Simplificada - S3 AWS)

ğŸ“¦ Projeto Data Pipeline Spotify (Arquitetura MedalhÃ£o Simplificada - S3 AWS)
â”œâ”€â”€ ğŸ“¥ Fonte de Dados: API Spotify
â”‚   â””â”€â”€ ğŸ“œ  Bloco Mage.ai (Python) - "Captura API Spotify"
â”‚       â””â”€â”€ ğŸ”— ConexÃ£o API REST Spotify (autenticaÃ§Ã£o e requisiÃ§Ã£o)
â”‚       â””â”€â”€ ğŸ“¤ ExtraÃ§Ã£o Data Bruto (JSON) - Artistas, MÃºsicas, Playlists, etc.
â”‚       â””â”€â”€ [Caixa de Texto: Bloco Python dedicado Ã  extraÃ§Ã£o eficiente e resiliente de dados da API Spotify. Implementar retentativas e tratamento de rate limits.]
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ Data Lake S3 AWS (MedalhÃ£o)
â”‚   â”œâ”€â”€ ğŸ“‚ Bronze (Raw) - s3://<seu-bucket>/spotify-datalake/bronze/
â”‚   â”‚   â””â”€â”€ ğŸ—„ï¸ Buckets S3 - OrganizaÃ§Ã£o por tipo de dado e data de ingestÃ£o
â”‚   â”‚       â””â”€â”€ ğŸ“œ JSON Bruto (Particionado por data) - s3://<seu-bucket>/spotify-datalake/bronze/artistas/YYYY/MM/DD/*.json
â”‚   â”‚           â””â”€â”€ [Caixa de Texto: Camada de landing zone. Dados em formato original da API, sem nenhuma transformaÃ§Ã£o. Foco em preservar a linhagem dos dados e permitir reprocessamento futuro.]
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Silver (Cleaned & Standardized) - s3://<seu-bucket>/spotify-datalake/silver/
â”‚   â”‚   â””â”€â”€ ğŸ—„ï¸ Buckets S3 - OrganizaÃ§Ã£o por tipo de dado e data de processamento
â”‚   â”‚       â””â”€â”€ ğŸ“œ Parquet Limpo e Padronizado (Particionado por data) - s3://<seu-bucket>/spotify-datalake/silver/musicas/YYYY/MM/DD/*.parquet
â”‚   â”‚           â””â”€â”€ [Caixa de Texto: Dados do Bronze limpos e padronizados usando Spark. RemoÃ§Ã£o de duplicatas, tratamento de nulos, conversÃ£o de tipos, padronizaÃ§Ã£o de formatos. Formato Parquet para eficiÃªncia em consultas analÃ­ticas.]
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Gold (Aggregated & Business Logic) - s3://<seu-bucket>/spotify-datalake/gold/ & ClickHouse (Data Warehouse)
â”‚   â”‚   â”œâ”€â”€ ğŸ—„ï¸ Buckets S3 - Dados agregados e histÃ³ricos (opcional para data lake completo)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“œ Parquet Agregado (Particionado por Ã¡rea de anÃ¡lise) - s3://<seu-bucket>/spotify-datalake/gold/tendencias_musicais/*.parquet
â”‚   â”‚   â”‚       â””â”€â”€ [Caixa de Texto: Camada Gold no S3 Ã© opcional, focada em data lake completo e histÃ³rico. Dados agregados para anÃ¡lises complexas e de longo prazo. Formato Parquet.]
â”‚   â”‚   â”œâ”€â”€ ğŸ—„ï¸ ClickHouse (Data Warehouse AnalÃ­tico) - banco_de_dados: spotify_gold
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ—ƒï¸ Tabelas ClickHouse - spotify_gold.artistas_populares, spotify_gold.generos_mais_escutados, etc.
â”‚   â”‚   â”‚   â””â”€â”€ [Caixa de Texto: Camada Gold otimizada para visualizaÃ§Ã£o e dashboards no Superset. Tabelas desnormalizadas e prÃ©-agregadas pelo DBT para consultas de alta performance. ClickHouse como data warehouse de alta velocidade.]
â”‚   â”‚
â”‚   â””â”€â”€ [Caixa de Texto: Data Lake S3 AWS (MedalhÃ£o): S3 como foundation da arquitetura. Escalabilidade, durabilidade e custo-efetividade do S3 para armazenar dados em todas as camadas do MedalhÃ£o. OrganizaÃ§Ã£o lÃ³gica em Bronze, Silver e Gold para qualidade e governanÃ§a de dados.]
â”‚
â”œâ”€â”€ âš™ï¸ Mage.ai - Orquestrador & ETL/ELT
â”‚   â”œâ”€â”€ ğŸ§© Pipelines de Dados Mage.ai
â”‚   â”‚   â”œâ”€â”€ ğŸŒŠ Pipeline IngestÃ£o Bronze - "Bronze Ingestion Pipeline"
â”‚   â”‚   â”‚   â””â”€â”€ [Caixa de Texto: Bloco Python "Captura API Spotify" -> Bloco Output S3 "Escrever Bronze S3". Agendamento: DiÃ¡rio/HorÃ¡rio. Pipeline de ELT (Extract-Load-Transform). ExtraÃ§Ã£o e carga bruta para S3.]
â”‚   â”‚   â”œâ”€â”€ âœ¨ Pipeline TransformaÃ§Ã£o Silver - "Silver Transformation Pipeline"
â”‚   â”‚   â”‚   â””â”€â”€ [Caixa de Texto: Bloco Input S3 "Ler Bronze S3" -> Bloco Spark "Limpeza e PadronizaÃ§Ã£o Spark" -> Bloco Output S3 "Escrever Silver S3". Agendamento: ApÃ³s IngestÃ£o Bronze. Pipeline ETL (Extract-Transform-Load). Leitura do Bronze, transformaÃ§Ã£o com Spark, carga no Silver.]
â”‚   â”‚   â”œâ”€â”€ ğŸ† Pipeline TransformaÃ§Ã£o Gold - DBT - "Gold DBT Transformation Pipeline"
â”‚   â”‚   â”‚   â””â”€â”€ [Caixa de Texto: Bloco DBT "Modelos DBT Gold". Modelos DBT (SQL/Python) orquestrados pelo Mage.ai. Leitura do Silver S3 -> TransformaÃ§Ã£o (AgregaÃ§Ã£o, LÃ³gica de NegÃ³cio) -> Output ClickHouse "Escrever Gold ClickHouse" (principal) e Output S3 "Escrever Gold S3" (opcional). Agendamento: ApÃ³s TransformaÃ§Ã£o Silver. Pipeline de TransformaÃ§Ã£o e Modelagem com DBT.]
â”‚   â”‚   â””â”€â”€ â±ï¸ Agendamento e Monitoramento Mage.ai
â”‚   â”‚       â””â”€â”€ [Caixa de Texto: Agendamento centralizado dos pipelines no Mage.ai. Monitoramento integrado da execuÃ§Ã£o, logs e alertas. Interface visual do Mage.ai para operacionalizaÃ§Ã£o e troubleshooting do pipeline.]
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ Blocos Python Mage.ai - "Blocos Python"
â”‚   â”‚   â””â”€â”€ ğŸ“œ CÃ³digo Python - ConexÃ£o API Spotify, funÃ§Ãµes auxiliares, etc.
â”‚   â”‚       â””â”€â”€ [Caixa de Texto: Blocos Python reutilizÃ¡veis dentro do Mage.ai para tarefas especÃ­ficas. CÃ³digo modular e versionado dentro do contexto do pipeline.]
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸš€ Blocos Spark Mage.ai - "Blocos Spark"
â”‚   â”‚   â””â”€â”€ ğŸ“œ CÃ³digo Spark - TransformaÃ§Ãµes Silver (limpeza, padronizaÃ§Ã£o)
â”‚   â”‚       â””â”€â”€ [Caixa de Texto: Blocos Spark para processamento distribuÃ­do e escalÃ¡vel das transformaÃ§Ãµes da camada Silver. Aproveitar o poder do Spark dentro do Mage.ai para grandes volumes de dados.]
â”‚   â”‚
â”‚   â””â”€â”€ [Caixa de Texto: Mage.ai - OrquestraÃ§Ã£o Centralizada e Desenvolvimento Ãgil: Mage.ai como orquestrador principal do pipeline de dados. Interface low-code/no-code para desenvolvimento rÃ¡pido e visual de pipelines. IntegraÃ§Ã£o nativa com Spark e DBT. Facilidade de agendamento, monitoramento e operacionalizaÃ§Ã£o.]
â”‚
â”œâ”€â”€ ğŸ› ï¸ DBT (Data Build Tool) - Modelagem Camada Gold
â”‚   â””â”€â”€ ğŸ“‚ Projetos DBT - "dbt_spotify_gold"
â”‚       â””â”€â”€ ğŸ“œ Modelos DBT (SQL & Python) - TransformaÃ§Ãµes Gold, agregaÃ§Ãµes, lÃ³gica de negÃ³cio
â”‚       â””â”€â”€ ğŸ§ª Testes DBT - Qualidade e integridade dos dados transformados
â”‚       â””â”€â”€ ğŸ“š DocumentaÃ§Ã£o DBT - Autogerada, lineage e dicionÃ¡rio de dados
â”‚       â””â”€â”€ [Caixa de Texto: DBT para Modelagem e TransformaÃ§Ã£o da Camada Gold: DBT para transformaÃ§Ãµes declarativas e versionadas. Foco na camada Gold para visualizaÃ§Ã£o e anÃ¡lise. Testes DBT para garantir a qualidade dos dados. DocumentaÃ§Ã£o para governanaÃ§a e colaboraÃ§Ã£o.]
â”‚
â”œâ”€â”€ ğŸ“Š Superset - VisualizaÃ§Ã£o & Dashboards
    â””â”€â”€ ğŸ¨ Dashboards Superset - "Dashboards AnalÃ­ticos Spotify"
        â””â”€â”€ ğŸ“ˆ VisualizaÃ§Ãµes Interativas - GrÃ¡ficos, tabelas, mapas, etc.
        â””â”€â”€ ğŸ”— ConexÃ£o Direta ClickHouse - Fonte de dados: Tabelas Gold ClickHouse
        â””â”€â”€ [Caixa de Texto: Superset para VisualizaÃ§Ã£o e ExploraÃ§Ã£o: Superset conectado diretamente ao ClickHouse (sem Trino para simplificar). Dashboards interativos e visualmente atraentes apresentando insights dos dados Spotify. Foco na experiÃªncia do usuÃ¡rio e storytelling com dados.]




Detalhes da Arquitetura
A arquitetura do projeto Ã© baseada no padrÃ£o MedalhÃ£o, uma abordagem comprovada para organizar dados em um data lake, garantindo qualidade e facilitando o consumo. Cada camada tem um propÃ³sito especÃ­fico:

*Â  Â Bronze (Raw):Â  Esta Ã© a camada inicial, onde os dados brutos da API do Spotify sÃ£o armazenados em seu formato original (JSON). O foco aqui Ã© a preservaÃ§Ã£o da linhagem dos dados, permitindo reprocessamento futuro caso necessÃ¡rio. Os dados sÃ£o particionados por data para otimizar o gerenciamento e consultas.

*Â  Â Silver (Cleaned & Standardized):Â  Nesta camada, os dados do Bronze passam por um processo de limpeza e padronizaÃ§Ã£o utilizando Spark. Isso inclui a remoÃ§Ã£o de duplicatas, tratamento de valores nulos, conversÃ£o de tipos de dados e padronizaÃ§Ã£o de formatos. O formato Parquet Ã© utilizado para otimizar a eficiÃªncia em consultas analÃ­ticas.

*Â  Â Gold (Aggregated & Business Logic) & ClickHouse (Data Warehouse):Â  A camada Gold representa os dados transformados e agregados, prontos para responder a perguntas de negÃ³cio e gerar insights.Â  Utilizamos o DBT para modelar esses dados, aplicando lÃ³gicas de negÃ³cio e realizando agregaÃ§Ãµes.

*Â  Â S3 (Opcional):Â  Uma parte da camada Gold pode ser armazenada no S3, em formato Parquet, para manter um data lake completo e histÃ³rico, ideal para anÃ¡lises de longo prazo e cenÃ¡rios futuros.
Â  Â  *Â  Â ClickHouse (Principal):Â  A principal parte da camada Gold Ã© carregada no ClickHouse, um data warehouse analÃ­tico de alta performance. As tabelas no ClickHouse sÃ£o desnormalizadas e prÃ©-agregadas pelo DBT, otimizadas para consultas rÃ¡pidas e visualizaÃ§Ã£o interativa no Superset. O ClickHouse atua como o data warehouse de alta velocidade para dashboards.

*Â  Â Mage.ai (Orquestrador & ETL/ELT):Â  O Mage.ai Ã© a espinha dorsal do pipeline, orquestrando todas as etapas de ingestÃ£o e transformaÃ§Ã£o.

*Â  Â Pipelines de Dados:Â  O Mage.ai permite criar pipelines visuais para cada etapa do MedalhÃ£o:
Â  Â  Â  Â  *Â  Â Bronze Ingestion Pipeline (ELT): Extrai dados da API Spotify e carrega brutos no S3 (Bronze).
Â  Â  Â  Â  *Â  Â Silver Transformation Pipeline (ETL): LÃª dados do S3 (Bronze), transforma com Spark (limpeza e padronizaÃ§Ã£o) e carrega no S3 (Silver).
Â  Â  Â  Â  *Â  Â Gold DBT Transformation Pipeline: Executa modelos DBT para ler dados do S3 (Silver), transformar (agregaÃ§Ã£o, lÃ³gica de negÃ³cio) e carregar no ClickHouse (Gold) e, opcionalmente, no S3 (Gold).

*Â  Â Agendamento e Monitoramento: O Mage.ai oferece agendamento centralizado para execuÃ§Ã£o automÃ¡tica dos pipelines e monitoramento integrado para garantir a confiabilidade do fluxo de dados.

*Â  Â Blocos Python e Spark: O Mage.ai integra-se nativamente com Python e Spark, permitindo criar blocos de cÃ³digo modularizados e reutilizÃ¡veis para tarefas especÃ­ficas de extraÃ§Ã£o, transformaÃ§Ã£o e processamento.

*Â  Â DBT (Data Build Tool) - Modelagem da Camada Gold:Â  O DBT Ã© utilizado para modelar e transformar os dados na camada Gold de forma declarativa e versionada.

*Â  Â Projetos DBT: Os modelos DBT sÃ£o organizados em projetos, definindo as transformaÃ§Ãµes SQL e Python, testes de qualidade de dados e documentaÃ§Ã£o.
Â  Â  *Â  Â Testes e DocumentaÃ§Ã£o: O DBT permite implementar testes para garantir a qualidade dos dados transformados e gera documentaÃ§Ã£o automÃ¡tica, facilitando a governanÃ§a e colaboraÃ§Ã£o no projeto.

*Â  Â Superset (VisualizaÃ§Ã£o & Dashboards):Â  O Superset Ã© conectado diretamente ao ClickHouse para criar dashboards interativos e visualmente atraentes.

*Â  Â Dashboards AnalÃ­ticos:Â  Dashboards no Superset apresentam insights relevantes dos dados do Spotify, como tendÃªncias musicais, popularidade de artistas e caracterÃ­sticas de mÃºsicas, com foco na experiÃªncia do usuÃ¡rio e storytelling com dados.

Getting Started (ExecuÃ§Ã£o Local com Docker Compose)
Para executar este projeto localmente, siga os passos abaixo:

PrÃ©-requisitos:

*Â  Â Docker instalado na sua mÃ¡quina.
*Â  Â Docker Compose instalado na sua mÃ¡quina.

Passos:

1.Â  Clone este repositÃ³rio:
Â  Â  bash git clone [link-para-o-seu-repositorio] cd [nome-do-repositorio]

2.Â  Configure as variÃ¡veis de ambiente (se necessÃ¡rio):
Â  Â  *Â  Â No momento, este projeto pode nÃ£o necessitar de variÃ¡veis de ambiente complexas para rodar localmente (ex: credenciais AWS para um Minio local, se vocÃª optar por usar no futuro).Â  No entanto, se a API do Spotify ou outras partes do projeto exigirem configuraÃ§Ã£o, vocÃª pode criar um arquivo .env na raiz do projeto e definir as variÃ¡veis lÃ¡.Â  O docker-compose.yml pode ser configurado para ler este arquivo.

3.Â  Execute o Docker Compose:
Â  Â  bash docker-compose up -d
Â  Â  Este comando irÃ¡ iniciar todos os serviÃ§os necessÃ¡rios (Mage.ai, ClickHouse, Superset) em containers Docker.

4.Â  Acesse as interfaces web:
Â  Â  *Â  Â Mage.ai UI:Â  Abra seu navegador e acesse http://localhost:6789.
Â  Â  *Â  Â Superset UI: Abra seu navegador e acesse http://localhost:8088.Â  (As credenciais iniciais do Superset geralmente sÃ£o admin/admin).
Â  Â  *Â  Â ClickHouse CLI (Opcional):Â  Para acessar a linha de comando do ClickHouse dentro do container (para exploraÃ§Ã£o e troubleshooting, se necessÃ¡rio):
Â  Â  Â  Â  bash docker exec -it clickhouse-server clickhouse-client

Executando o Data Pipeline no Mage.ai
1.Â  Acesse a UI do Mage.ai: http://localhost:6789.
2.Â  Navegue atÃ© a seÃ§Ã£o de Pipelines.
3.Â  Execute os pipelines na ordem correta:
Â  Â  *Â  Â Bronze Ingestion Pipeline: Para iniciar a extraÃ§Ã£o de dados da API do Spotify e carregar na camada Bronze do S3 (local, se estiver usando Minio, ou AWS S3 se configurado).
Â  Â  *Â  Â Silver Transformation Pipeline: ApÃ³s a ingestÃ£o do Bronze, execute este pipeline para limpar e padronizar os dados e carregar na camada Silver do S3.
Â  Â  *Â  Â Gold DBT Transformation Pipeline:Â  Por fim, execute este pipeline (DBT) para transformar e agregar os dados da camada Silver e carregar na camada Gold (S3 e ClickHouse).
4.Â  Monitore a execuÃ§Ã£o dos pipelines:Â  O Mage.ai oferece uma interface visual para acompanhar o status de cada pipeline, logs e identificar possÃ­veis erros.

Explorando Dashboards no Superset
1.Â  Acesse a UI do Superset: http://localhost:8088.
2.Â  FaÃ§a login com as credenciais iniciais (geralmente admin/admin).
3.Â  Navegue atÃ© a seÃ§Ã£o de Dashboards.
4.Â  Abra os Dashboards AnalÃ­ticos Spotify:Â  Explore os dashboards prÃ©-criados (ou crie seus prÃ³prios!) para visualizar os insights gerados a partir dos dados do Spotify.Â  Exemplos de dashboards podem incluir:
Â  Â  *Â  Â TendÃªncias Musicais por GÃªnero ao longo do tempo.
Â  Â  *Â  Â Ranking de Artistas Mais Populares.
Â  Â  *Â  Â DistribuiÃ§Ã£o de CaracterÃ­sticas de Ãudio das MÃºsicas por GÃªnero.
Â  Â  *Â  Â E muito mais!

PrÃ³ximos Passos e Melhorias Futuras
Este projeto pode ser expandido e aprimorado de diversas formas:

*Â  Â IntegraÃ§Ã£o com Machine Learning: Adicionar modelos de machine learning para recomendaÃ§Ã£o de mÃºsicas, anÃ¡lise de sentimento em letras, etc.
*Â  Â Dados em Tempo Real (Streaming): Explorar a possibilidade de trabalhar com dados em tempo real ou quase real time da API do Spotify para dashboards dinÃ¢micos.
*Â  Â Fontes de Dados Adicionais: Combinar dados do Spotify com outras fontes de dados (redes sociais, dados demogrÃ¡ficos, etc.) para anÃ¡lises mais ricas.
*Â  Â Aprimoramento dos Dashboards:Â  Criar dashboards mais interativos e personalizados no Superset, explorando diferentes tipos de visualizaÃ§Ãµes e mÃ©tricas.
*Â  Â ImplementaÃ§Ã£o de CI/CD:Â  Configurar um pipeline de CI/CD para automatizar testes, build e deployment do pipeline Mage.ai.
*Â  Â Monitoramento AvanÃ§ado: Implementar um sistema de monitoramento mais robusto com alertas e mÃ©tricas detalhadas do pipeline.

Apresentando no LinkedIn
Para destacar este projeto no seu perfil do LinkedIn e impressionar recrutadores:

*Â  Â TÃ­tulo do Projeto: Utilize um tÃ­tulo chamativo como "Data Pipeline MedalhÃ£o para AnÃ¡lise Musical com Spotify API, Mage.ai, Spark, ClickHouse, Superset e DBT".
*Â  Â DescriÃ§Ã£o Detalhada: Na seÃ§Ã£o de projetos do LinkedIn, forneÃ§a uma descriÃ§Ã£o clara e concisa do projeto, destacando as tecnologias utilizadas, a arquitetura MedalhÃ£o e os principais insights que vocÃª obteve.
*Â  Â Link para o GitHub: Inclua um link direto para este repositÃ³rio do GitHub para que recrutadores possam explorar o cÃ³digo e a documentaÃ§Ã£o.
*Â  Â DemonstraÃ§Ã£o Visual: Adicione screenshots dos dashboards do Superset no README do GitHub e, idealmente, inclua um vÃ­deo curto (screencast) demonstrando os dashboards em aÃ§Ã£o.
*Â  Â Palavras-chave: Utilize palavras-chave relevantes para engenharia de dados (Data Engineering, Data Pipeline, Cloud, AWS, Mage.ai, Spark, DBT, ClickHouse, Superset, Data Lake, Data Warehouse, etc.) na descriÃ§Ã£o do projeto e no seu perfil do LinkedIn.
*Â  Â Compartilhe um Post: ApÃ³s publicar o projeto, faÃ§a um post no LinkedIn compartilhando com sua rede. Explique o que vocÃª construiu, as tecnologias utilizadas e convide as pessoas a conferirem o repositÃ³rio no GitHub.

Disclaimer
Este projeto Ã© desenvolvido para fins educacionais e de demonstraÃ§Ã£o de habilidades em engenharia de dados.Â  O uso da API do Spotify estÃ¡ sujeito aos termos de serviÃ§o e limitaÃ§Ãµes de rate limiting da plataforma.Â  Certifique-se de respeitar a privacidade dos dados e os termos de uso da API do Spotify.

LicenÃ§a
[Escolha sua licenÃ§a - Exemplo: MIT License] (Opcional)

Autor
Arthur Maia Graf - (https://github.com/arthurmgraf)
